{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "btVG8Bhv0iPR"
      },
      "outputs": [],
      "source": [
        "# https://www.kaggle.com/code/tiiktak/fashion-mnist-with-alexnet-in-pytorch-92-accuracy/notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NtamfbiX0iPT"
      },
      "outputs": [],
      "source": [
        "# nn.Linear(28*28, 512) = w < R^(784x512)\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import Dataset, DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bGcI24cu0iPV",
        "outputId": "c30a31a9-69a3-48d5-eb47-b8e2bce87969",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# training batches of our network\n",
        "epochs = 10\n",
        "# size of each batch\n",
        "batch_size = 512\n",
        "\n",
        "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "print(torch.__version__)\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "H5PI0R680iPV"
      },
      "outputs": [],
      "source": [
        "# prepare datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "transform = transforms.Compose([transforms.Resize(227), ToTensor()]) # 227x227 : input image but fashionMNIST's input image : 28x28\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "validation_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GP_dalyM0iPY"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "training_loader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "validation_loader = DataLoader(validation_data, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kCWsHIIs0iPa",
        "outputId": "f2911438-052f-40aa-b6d1-3e02f49ad3b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sandal\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# helper function to show an image\n",
        "def matplotlib_imshow(img):\n",
        "    img = img.mean(dim=0)\n",
        "    img = img / 2 + 0.5\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(npimg, cmap=\"Greys\")\n",
        "    \n",
        "# get some random training images\n",
        "dataiter = iter(training_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# create grid of images\n",
        "img_grid = torchvision.utils.make_grid(images[0])\n",
        "\n",
        "# show images & labels\n",
        "matplotlib_imshow(img_grid)\n",
        "print(class_names[labels[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "W0tfIsVr0iPb"
      },
      "outputs": [],
      "source": [
        "class fashion_mnist_alexnet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Sequential( # x < R^(227x227x1)  | w1 < R^(11x11x1x96) == 55(which means (227-11)/4)x55x96\n",
        "            nn.Conv2d(in_channels=1, out_channels=96, kernel_size=11, stride=4, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2) # (55-3+1)/2 = 26.5 = 27\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(96, 256, 5, 1, 2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(3, 2)\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(256, 384, 3, 1, 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(384, 384, 3, 1, 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(384, 256, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(3, 2)\n",
        "        )\n",
        "        \n",
        "        self.fc1 = nn.Linear(256 * 6 * 6, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.conv5(out) # 64x4096x1x1\n",
        "        out = out.view(out.size(0), -1) # 64x4096\n",
        "        \n",
        "        out = F.relu(self.fc1(out))\n",
        "        out = F.dropout(out, 0.5)\n",
        "        out = F.relu(self.fc2(out))\n",
        "        out = F.dropout(out, 0.5)\n",
        "        out = self.fc3(out)\n",
        "        out = F.log_softmax(out, dim=1)\n",
        "        \n",
        "        return out\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "E85Vgtp10iPd"
      },
      "outputs": [],
      "source": [
        "model = fashion_mnist_alexnet().to(device)\n",
        "criterion = F.nll_loss\n",
        "optimizer = optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary as summary_\n",
        "\n",
        "summary_(model, (1,227,227), batch_size)"
      ],
      "metadata": {
        "id": "VrBL396BB51S",
        "outputId": "08b898e2-981b-4f4d-a241-23fe0d48709c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [512, 96, 55, 55]          11,712\n",
            "              ReLU-2          [512, 96, 55, 55]               0\n",
            "         MaxPool2d-3          [512, 96, 27, 27]               0\n",
            "            Conv2d-4         [512, 256, 27, 27]         614,656\n",
            "              ReLU-5         [512, 256, 27, 27]               0\n",
            "         MaxPool2d-6         [512, 256, 13, 13]               0\n",
            "            Conv2d-7         [512, 384, 13, 13]         885,120\n",
            "              ReLU-8         [512, 384, 13, 13]               0\n",
            "            Conv2d-9         [512, 384, 13, 13]       1,327,488\n",
            "             ReLU-10         [512, 384, 13, 13]               0\n",
            "           Conv2d-11         [512, 256, 13, 13]         884,992\n",
            "             ReLU-12         [512, 256, 13, 13]               0\n",
            "        MaxPool2d-13           [512, 256, 6, 6]               0\n",
            "           Linear-14                [512, 4096]      37,752,832\n",
            "           Linear-15                [512, 4096]      16,781,312\n",
            "           Linear-16                  [512, 10]          40,970\n",
            "================================================================\n",
            "Total params: 58,299,082\n",
            "Trainable params: 58,299,082\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 100.64\n",
            "Forward/backward pass size (MB): 5589.16\n",
            "Params size (MB): 222.39\n",
            "Estimated Total Size (MB): 5912.20\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "67xvFkaM0iPd"
      },
      "outputs": [],
      "source": [
        "# def train(model, device, train_loader, optimizer, epoch):\n",
        "#     model.train()\n",
        "#     for batch_idx, (data, target) in enumerate(train_loader):\n",
        "#         target = target.type(torch.LongTensor)\n",
        "#         data, target = data.to(device), target.to(device)\n",
        "#         optimizer.zero_grad()\n",
        "#         output = model(data)\n",
        "#         loss = criterion(output, target) # criterion = MEA or MSE\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         if (batch_idx + 1) % 50 == 0:\n",
        "#             print(\"Train Epoch:{} [{}/{} ({:/0f}%)]\\tLoss: {:.6f}\".format(\n",
        "#                 epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "#                 100. * batch_idx / len(train_loader), loss.item()\n",
        "#             ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nSv0mw3S0iPf"
      },
      "outputs": [],
      "source": [
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        target = target.type(torch.LongTensor)\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if (batch_idx + 1) % 30 == 0:\n",
        "            print(\"Train Epoch:{} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zrknYcxS0iPf"
      },
      "outputs": [],
      "source": [
        "# def test(model, device, test_loader):\n",
        "#     model.eval()\n",
        "#     test_loss = 0\n",
        "#     correct = 0\n",
        "#     with torch.no_grad():\n",
        "#         for data, target in test_loader:\n",
        "#             data, target = data.to(device), target.to(device)\n",
        "#             output = model(data)\n",
        "#             test_loss += criterion(output, target, reduction='sum').item()\n",
        "#             pred = output.max(1, keepdim=True)[1]\n",
        "#             correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        \n",
        "#         test_loss /= len(test_loader.dataset)\n",
        "#         print(\"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n",
        "#             test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)\n",
        "#         ))\n",
        "#         print('='*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9TZO7C4u0iPh"
      },
      "outputs": [],
      "source": [
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target, reduction='sum').item()\n",
        "            pred = output.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        test_loss /= len(test_loader.dataset)  # -> mean\n",
        "        print(\"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n",
        "            test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
        "        print('='*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ppu8XJbx0iPh",
        "outputId": "9c93a9b6-e2ab-4db8-bab6-151a00ce2eb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:1 [1856/60000 (3%)]\tLoss: 1.083595\n",
            "Train Epoch:1 [3776/60000 (6%)]\tLoss: 0.883576\n",
            "Train Epoch:1 [5696/60000 (9%)]\tLoss: 0.882255\n",
            "Train Epoch:1 [7616/60000 (13%)]\tLoss: 0.647190\n",
            "Train Epoch:1 [9536/60000 (16%)]\tLoss: 0.540642\n",
            "Train Epoch:1 [11456/60000 (19%)]\tLoss: 0.678961\n",
            "Train Epoch:1 [13376/60000 (22%)]\tLoss: 0.735797\n",
            "Train Epoch:1 [15296/60000 (25%)]\tLoss: 0.665839\n",
            "Train Epoch:1 [17216/60000 (29%)]\tLoss: 0.475991\n",
            "Train Epoch:1 [19136/60000 (32%)]\tLoss: 0.489610\n",
            "Train Epoch:1 [21056/60000 (35%)]\tLoss: 0.649605\n",
            "Train Epoch:1 [22976/60000 (38%)]\tLoss: 0.480917\n",
            "Train Epoch:1 [24896/60000 (41%)]\tLoss: 0.381356\n",
            "Train Epoch:1 [26816/60000 (45%)]\tLoss: 0.685879\n",
            "Train Epoch:1 [28736/60000 (48%)]\tLoss: 0.345098\n",
            "Train Epoch:1 [30656/60000 (51%)]\tLoss: 0.412779\n",
            "Train Epoch:1 [32576/60000 (54%)]\tLoss: 0.270462\n",
            "Train Epoch:1 [34496/60000 (57%)]\tLoss: 0.579772\n",
            "Train Epoch:1 [36416/60000 (61%)]\tLoss: 0.564830\n",
            "Train Epoch:1 [38336/60000 (64%)]\tLoss: 0.318793\n",
            "Train Epoch:1 [40256/60000 (67%)]\tLoss: 0.410780\n",
            "Train Epoch:1 [42176/60000 (70%)]\tLoss: 0.407890\n",
            "Train Epoch:1 [44096/60000 (73%)]\tLoss: 0.401700\n",
            "Train Epoch:1 [46016/60000 (77%)]\tLoss: 0.411252\n",
            "Train Epoch:1 [47936/60000 (80%)]\tLoss: 0.313879\n",
            "Train Epoch:1 [49856/60000 (83%)]\tLoss: 0.270489\n",
            "Train Epoch:1 [51776/60000 (86%)]\tLoss: 0.307196\n",
            "Train Epoch:1 [53696/60000 (89%)]\tLoss: 0.268110\n",
            "Train Epoch:1 [55616/60000 (93%)]\tLoss: 0.118300\n",
            "Train Epoch:1 [57536/60000 (96%)]\tLoss: 0.227598\n",
            "Train Epoch:1 [59456/60000 (99%)]\tLoss: 0.330718\n",
            "\n",
            "Test set: Average loss: 0.3759, Accuracy: 8590/10000 (86%)\n",
            "\n",
            "==================================================\n",
            "Train Epoch:2 [1856/60000 (3%)]\tLoss: 0.303968\n",
            "Train Epoch:2 [3776/60000 (6%)]\tLoss: 0.593006\n",
            "Train Epoch:2 [5696/60000 (9%)]\tLoss: 0.294733\n",
            "Train Epoch:2 [7616/60000 (13%)]\tLoss: 0.364520\n",
            "Train Epoch:2 [9536/60000 (16%)]\tLoss: 0.414996\n",
            "Train Epoch:2 [11456/60000 (19%)]\tLoss: 0.260808\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1, epochs+1):\n",
        "    train(model, device, training_loader, optimizer, epoch)\n",
        "    test(model, device, validation_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-L6nQ-6h8pGQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "c200132d1e6ad0d08ee4f5a6aa73cd3fb0821d2e05edf12ce927a5bc1afafe0a"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('tf2.8')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "alexnet_pytorch.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}