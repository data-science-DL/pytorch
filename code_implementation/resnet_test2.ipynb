{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # 파이썬을 이용해 파일을 복사하거나 디렉터리를 생성하고 특정 디렉터리 내의 파일 목록을 구하고자 할 때 사용\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torchvision # torchvision package : 컴퓨터 비전을 위한 유명 데이터셋, 모델 아키텍처, 이미지 변형등을 포함\n",
    "import torch.nn as nn # nn : neural netwroks (define class) attribute를 활용해 state를 저장하고 활용\n",
    "import torch.optim as optim # 최적화 알고리즘\n",
    "import torch.nn.functional as F # (define function) 인스턴스화 시킬 필요없이 사용 가능\n",
    "from PIL import Image\n",
    "from torchvision import transforms, datasets # transforms : 데이터를 조작하고 학습에 적합하게 만듦.\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# dataset : 샘플과 정답(label)을 저장\n",
    "# DataLoader : Dataset 을 샘플에 쉽게 접근할 수 있도록 순회 가능한 객체(iterable)로 감싼다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# torch.nn : 딥러닝 모델에 필요한 모듈이 모여 있는 패키지\n",
    "import torch.nn as nn\n",
    "\n",
    "class block(nn.Module):\n",
    "    # __init__는 클래스 내의 생성자라 불리고 초기화를 위한 함수이다.\n",
    "    # self는 인스턴스 자신이다.\n",
    "    def __init__(self, in_channels, out_channels, identity_downsample=None, stride=1):\n",
    "        # super(모델명, self).__init__() 형태로 호출\n",
    "        # 위처럼 호출해서 nn.Module.__init__()을 실행\n",
    "        super(block, self).__init__()\n",
    "        self.expansion = 4 # 확장\n",
    "        # nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding) 순서로 정의\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        # downsample은 forward시 f(x)+x의 residual을 구현할 경우 f(x)와 x의 텐서사이즈가 다를 때 사용한다.\n",
    "        self.identity_downsample = identity_downsample\n",
    "    \n",
    "    # 네트워크 구조를 정의하는 순방향 함수\n",
    "    # 여기서는 한가지 입력만 허용하고 있다.\n",
    "    def forward(self, x):\n",
    "        # identity에 x 저장\n",
    "        identity = x\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        \n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "\n",
    "        # x(=출력값)에 identity 값 더함    \n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module): # resnet50 : [3, 4, 6, 3]\n",
    "    def __init__(self, block, layers, image_channels, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # ResNet layers\n",
    "        # self._make_layer를 이용하여 residual block들을 쌓는다.\n",
    "        # 필터의 개수는 각 block들을 거치면서 2배씩 늘어난다. (64->128->256->512)\n",
    "        self.layer1 = self._make_layer(block, layers[0], out_channels=64, stride=1)\n",
    "        self.layer2 = self._make_layer(block, layers[1], out_channels=128, stride=2)\n",
    "        self.layer3 = self._make_layer(block, layers[2], out_channels=256, stride=2)\n",
    "        self.layer4 = self._make_layer(block, layers[3], out_channels=512, stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1)) # (n, 512, 1, 1)의 텐서로 만든다.\n",
    "        self.fc = nn.Linear(512*4, num_classes) # fully-connected layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1) # send it into the fully connected layer\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    # _make_layer에서 residual block 생성\n",
    "    # block : 앞에 정의한 block 클래스\n",
    "    # num_residual_blocks : layer 반복해서 쌓는 개수\n",
    "    def _make_layer(self, block, num_residual_blocks, out_channels, stride):\n",
    "        identity_downsample = None\n",
    "        layers = []\n",
    "        \n",
    "        # downsampling이 필요한 경우 identity_downsample 생성\n",
    "            # 1. stride가 1이 아닐 때\n",
    "            # 2. self.in_channels가 out_channels*4와 크기가 맞지 않을 때\n",
    "        if stride != 1 or self.in_channels != out_channels * 4:\n",
    "            identity_downsample = nn.Sequential(nn.Conv2d(self.in_channels, out_channels*4, kernel_size=1, stride=stride),\n",
    "            nn.BatchNorm2d(out_channels*4))\n",
    "        \n",
    "        layers.append(block(self.in_channels, out_channels, identity_downsample, stride))\n",
    "        self.in_channels = out_channels*4 # 256\n",
    "        \n",
    "        for i in range(num_residual_blocks - 1):\n",
    "            layers.append(block(self.in_channels, out_channels)) # 256 -> 64, 64*4 (256) again\n",
    "        \n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "def ResNet50(img_channels=1, num_classes=10):\n",
    "    return ResNet(block, [3, 4, 6, 3], img_channels, num_classes)\n",
    "\n",
    "def ResNet101(img_channels=1, num_classes=10):\n",
    "    return ResNet(block, [3, 4, 23, 3], img_channels, num_classes)\n",
    "\n",
    "def ResNet152(img_channels=1, num_classes=10):\n",
    "    return ResNet(block, [3, 8, 36, 3], img_channels, num_classes)\n",
    "\n",
    "def test():\n",
    "    net = ResNet101()\n",
    "    x = torch.randn(2, 1, 224, 224)\n",
    "    y = net(x).to('cuda')\n",
    "    print(y.shape)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_resnet = ResNet101()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 10])\n",
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): block(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): block(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): block(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): block(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): block(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): block(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (3): block(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): block(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (3): block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (4): block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (5): block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (6): block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (7): block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (8): block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (9): block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (10): block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (11): block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (12): block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (13): block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (14): block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (15): block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (16): block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (17): block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (18): block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (19): block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (20): block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (21): block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (22): block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): block(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): block(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): block(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn((16,1,224,224))\n",
    "output = my_resnet(input)\n",
    "print(output.shape)\n",
    "\n",
    "print(my_resnet)\n",
    "\n",
    "# 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0+cu113\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "epochs = 10 # 훈련 반복수\n",
    "batch_size = 512 # 배치 크기\n",
    "\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\") # device 정의\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'] # 총 10개의 클래스\n",
    "\n",
    "print(torch.__version__)\n",
    "print(device)\n",
    "\n",
    "# 결과\n",
    "# 1.10.0+cu111\n",
    "# cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(227), # Compose : transforms 리스트 구성\n",
    "    # 227x227 : input image(in alexnet) but fashionMNIST's input image : 28x28\n",
    "    transforms.ToTensor()]) # ToTensor : PIL image or numpy.ndarray를 tensor로 바꿈\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\", # data가 저장될 경로(path)\n",
    "    train=True, # training dataset\n",
    "    download=True, # 인터넷으로부터 데이터 다운\n",
    "    transform=transform # feature 및 label 변환(transformation) 지정\n",
    ")\n",
    "\n",
    "validation_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False, # test dataset\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (class) DataLoader(dataset, batch_size, shuffle, ...)\n",
    "training_loader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "validation_loader = DataLoader(validation_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sandal\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def matplotlib_imshow(img):\n",
    "    img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(npimg, cmap=\"Greys\")\n",
    "    \n",
    "# get some random training images\n",
    "dataiter = iter(training_loader) # iter(호출가능한객체, 반복을끝낼값)\n",
    "images, labels = dataiter.next() # next() : 반복할 수 있을 때는 해당 값을 출력하고, 반복이 끝났을 때는 기본값을 출력\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images[0]) # make_grid : 이미지의 그리드 생성\n",
    "\n",
    "# show images & labels\n",
    "matplotlib_imshow(img_grid)\n",
    "print(class_names[labels[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = my_resnet.to(device) # to()로 모델에 gpu 사용\n",
    "criterion = F.nll_loss # nll_loss : negative log likelihood loss\n",
    "optimizer = optim.Adam(model.parameters()) # model(신경망) 파라미터를 optimizer에 전달해줄 때 nn.Module의 parameters() 메소드를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # enumberate() : 인덱스와 원소로 이루어진 튜플(tuple)을 만들어줌\n",
    "        target = target.type(torch.LongTensor)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad() # 항상 backpropagation 하기전에 미분(gradient)을 zero로 만들어주고 시작해야 한다.\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target) # criterion = loss_fn\n",
    "        loss.backward() # Computes the gradient of current tensor w.r.t. graph leaves\n",
    "        optimizer.step() # step() : 파라미터를 업데이트함\n",
    "        if (batch_idx + 1) % 30 == 0:\n",
    "            print(\"Train Epoch:{} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target, reduction='sum').item()\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)  # -> mean\n",
    "        print(\"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n",
    "            test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
    "        print('='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 58.00 MiB (GPU 0; 8.00 GiB total capacity; 7.02 GiB already allocated; 0 bytes free; 7.32 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mf:\\pytorch\\code_implementation\\resnet_test2.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/pytorch/code_implementation/resnet_test2.ipynb#ch0000014?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, epochs\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/pytorch/code_implementation/resnet_test2.ipynb#ch0000014?line=1'>2</a>\u001b[0m     train(model, device, training_loader, optimizer, epoch)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/pytorch/code_implementation/resnet_test2.ipynb#ch0000014?line=2'>3</a>\u001b[0m     test(model, device, validation_loader)\n",
      "\u001b[1;32mf:\\pytorch\\code_implementation\\resnet_test2.ipynb Cell 12'\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/pytorch/code_implementation/resnet_test2.ipynb#ch0000012?line=5'>6</a>\u001b[0m data, target \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device), target\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/pytorch/code_implementation/resnet_test2.ipynb#ch0000012?line=6'>7</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad() \u001b[39m# 항상 backpropagation 하기전에 미분(gradient)을 zero로 만들어주고 시작해야 한다.\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/pytorch/code_implementation/resnet_test2.ipynb#ch0000012?line=7'>8</a>\u001b[0m output \u001b[39m=\u001b[39m model(data)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/pytorch/code_implementation/resnet_test2.ipynb#ch0000012?line=8'>9</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, target) \u001b[39m# criterion = loss_fn\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/pytorch/code_implementation/resnet_test2.ipynb#ch0000012?line=9'>10</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward() \u001b[39m# Computes the gradient of current tensor w.r.t. graph leaves\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mf:\\pytorch\\code_implementation\\resnet_test2.ipynb Cell 3'\u001b[0m in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/pytorch/code_implementation/resnet_test2.ipynb#ch0000003?line=26'>27</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer1(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/pytorch/code_implementation/resnet_test2.ipynb#ch0000003?line=27'>28</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer2(x)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/pytorch/code_implementation/resnet_test2.ipynb#ch0000003?line=28'>29</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer3(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/pytorch/code_implementation/resnet_test2.ipynb#ch0000003?line=29'>30</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer4(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/pytorch/code_implementation/resnet_test2.ipynb#ch0000003?line=31'>32</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavgpool(x)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\torch\\nn\\modules\\container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/container.py?line=140'>141</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/container.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mf:\\pytorch\\code_implementation\\resnet_test2.ipynb Cell 2'\u001b[0m in \u001b[0;36mblock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/pytorch/code_implementation/resnet_test2.ipynb#ch0000002?line=33'>34</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn2(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/pytorch/code_implementation/resnet_test2.ipynb#ch0000002?line=34'>35</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/pytorch/code_implementation/resnet_test2.ipynb#ch0000002?line=35'>36</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv3(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/pytorch/code_implementation/resnet_test2.ipynb#ch0000002?line=36'>37</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn3(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/pytorch/code_implementation/resnet_test2.ipynb#ch0000002?line=38'>39</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39midentity_downsample \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\torch\\nn\\modules\\conv.py:447\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/conv.py?line=445'>446</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/conv.py?line=446'>447</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\torch\\nn\\modules\\conv.py:443\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/conv.py?line=438'>439</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/conv.py?line=439'>440</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/conv.py?line=440'>441</a>\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/conv.py?line=441'>442</a>\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/conv.py?line=442'>443</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    <a href='file:///c%3A/Users/poeun/anaconda3/envs/tf2.8/lib/site-packages/torch/nn/modules/conv.py?line=443'>444</a>\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 58.00 MiB (GPU 0; 8.00 GiB total capacity; 7.02 GiB already allocated; 0 bytes free; 7.32 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    train(model, device, training_loader, optimizer, epoch)\n",
    "    test(model, device, validation_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.8",
   "language": "python",
   "name": "tf2.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
